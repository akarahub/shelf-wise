{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10941,
     "status": "ok",
     "timestamp": 1733591452089,
     "user": {
      "displayName": "akara",
      "userId": "03294495074658875410"
     },
     "user_tz": -120
    },
    "id": "bKZk2VBLGe7I"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# YAML config\n",
    "try:\n",
    "    with open(r\".\\config.yaml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "except Exception as e:\n",
    "    raise\n",
    "\n",
    "# Logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(funcName)s - %(message)s\",\n",
    "    filename=config[\"log_dir\"] +\n",
    "    f\"{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.log\",\n",
    "    filemode=\"w\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Config file and logger setup completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "try:\n",
    "    ratings_df = pd.read_csv(config[\"data_path\"])\n",
    "    logger.info(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(f\"Data file not found at: {config[\"data_path\"]}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "ratings_df[\"Book-Rating\"] = ratings_df[\"Book-Rating\"].astype(float)\n",
    "\n",
    "ratings_df[\"User-ID\"] = pd.Categorical(ratings_df[\"User-ID\"])\n",
    "user_ids = ratings_df[\"User-ID\"].cat.codes\n",
    "ratings_df[\"new_user\"] = user_ids\n",
    "ratings_df\n",
    "\n",
    "ratings_df[\"ISBN\"] = pd.Categorical(ratings_df[\"ISBN\"])\n",
    "book_ids = ratings_df[\"ISBN\"].cat.codes\n",
    "ratings_df[\"new_ISBN\"] = book_ids\n",
    "ratings_df\n",
    "\n",
    "ratings_df = ratings_df.drop([\"User-ID\", \"ISBN\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Scaling\n",
    "scaler = MinMaxScaler()\n",
    "ratings_df[\"Book-Rating\"] = scaler.fit_transform(ratings_df[[\"Book-Rating\"]])\n",
    "\n",
    "\n",
    "user_ids = ratings_df[\"new_user\"].values\n",
    "book_ids = ratings_df[\"new_ISBN\"].values\n",
    "ratings = ratings_df[\"Book-Rating\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "try:\n",
    "    user_ids, book_ids, ratings = shuffle(\n",
    "        user_ids, book_ids, ratings, random_state=42)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error shuffling data: {e}\")\n",
    "    raise\n",
    "\n",
    "ntrain = int(0.8 * len(ratings))\n",
    "train_user = user_ids[:ntrain]\n",
    "train_book = book_ids[:ntrain]\n",
    "train_ratings = ratings[:ntrain]\n",
    "\n",
    "test_user = user_ids[ntrain:]\n",
    "test_book = book_ids[ntrain:]\n",
    "test_ratings = ratings[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "def build_model(num_users, num_books, embedding_size):\n",
    "    \"\"\"Returns the model with given layers.\"\"\"\n",
    "    u = tf.keras.Input(shape=(1,), name=\"user_input\")\n",
    "    m = tf.keras.Input(shape=(1,), name=\"book_input\")\n",
    "\n",
    "    u_emb = tf.keras.layers.Embedding(\n",
    "        num_users, embedding_size, name=\"user_embedding\")(u)\n",
    "    m_emb = tf.keras.layers.Embedding(\n",
    "        num_books, embedding_size, name=\"book_embedding\")(m)\n",
    "\n",
    "    u_emb = tf.keras.layers.Flatten()(u_emb)\n",
    "    m_emb = tf.keras.layers.Flatten()(m_emb)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate()([u_emb, m_emb])\n",
    "    x = tf.keras.layers.Dense(embedding_size * 2, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(embedding_size, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(embedding_size, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(embedding_size, activation=\"relu\")(x)\n",
    "    output = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=[u, m], outputs=output)\n",
    "\n",
    "\n",
    "model = build_model(len(set(user_ids)), len(\n",
    "    set(book_ids)), config[\"embedding_size\"])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=config[\"learning_rate\"]), loss=\"mean_squared_error\", metrics=[\"mean_absolute_error\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "try:\n",
    "    r = model.fit(x=[train_user, train_book], y=train_ratings, epochs=config[\"num_epochs\"],\n",
    "                  batch_size=config[\"batch_size\"], validation_data=([test_user, test_book], test_ratings))\n",
    "    logger.info(\n",
    "        f\"Loss history: {r.history[\"loss\"]}, val_loss history: {r.history[\"val_loss\"]}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during model training: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Saving\n",
    "try:\n",
    "    model.save(\"model.keras\")\n",
    "    logger.info(\"Model saved successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error saving model: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNMSa3wQ6aqvg/pbwbLm7AC",
   "mount_file_id": "1gOnZn0KEu67nIJYEbf75wlbI2eD43IKy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
